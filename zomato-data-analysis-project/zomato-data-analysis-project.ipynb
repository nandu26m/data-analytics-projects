{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNOvtpGG/mKlUT6y4tIDcyP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nandu26m/data-analytics-projects/blob/main/zomato-data-analysis-project/zomato-data-analysis-project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Cleaning and Transformation in Pandas\n",
        "\n",
        "We will perform the following tasks:\n",
        "\n",
        "1. Deleting redundant columns\n",
        "2. Renaming columns\n",
        "3. Dropping duplicates\n",
        "4. Cleaning individual columns\n",
        "5. Handling missing values (`NaN`)\n",
        "6. Applying additional data transformations\n",
        "\n",
        "---\n",
        "\n",
        "## Install and Load Data\n",
        "\n",
        "```python\n",
        "!pip install opendatasets\n",
        "\n",
        "import pandas as pd\n",
        "import opendatasets as od\n",
        "\n",
        "print(pd.__version__)\n",
        "\n",
        "# Download dataset from Kaggle\n",
        "od.download(\"https://www.kaggle.com/datasets/rishikeshkonapure/zomato\")\n",
        "\n",
        "# Load CSV file\n",
        "data = pd.read_csv(\"/content/zomato/zomato.csv\")\n",
        "\n",
        "# Inspect data\n",
        "data.head(2)\n",
        "data.columns\n",
        "data.info()\n",
        "data.shape\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## 1️. Deleting Redundant Columns\n",
        "\n",
        "Redundant columns do not add value to analysis and can slow down processing.\n",
        "\n",
        "### Approach 1: Select Only Needed Columns\n",
        "\n",
        "```python\n",
        "columns_to_keep = ['name', 'online_order', 'book_table', 'rate', 'dish_liked', 'approx_cost(for two people)']\n",
        "modified_data = data[columns_to_keep]\n",
        "modified_data.head()\n",
        "```\n",
        "\n",
        "### Approach 2: Drop Unwanted Columns\n",
        "\n",
        "```python\n",
        "columns_to_drop = ['url', 'address', 'votes', 'phone', 'location',\n",
        "                   'rest_type', 'cuisines', 'reviews_list', 'menu_item',\n",
        "                   'listed_in(type)', 'listed_in(city)']\n",
        "\n",
        "data.drop(columns=columns_to_drop, inplace=True)\n",
        "data.head()\n",
        "```\n",
        "\n",
        "> **Tip:** Always review columns before dropping to avoid losing useful information.\n",
        "\n",
        "---\n",
        "\n",
        "## 2️⃣ Renaming Columns\n",
        "\n",
        "Renaming improves readability and consistency.\n",
        "\n",
        "### Rename Specific Columns\n",
        "\n",
        "```python\n",
        "data.rename(columns={\n",
        "    \"old_name1\": \"new_name1\",\n",
        "    \"old_name2\": \"new_name2\"\n",
        "}, inplace=True)\n",
        "```\n",
        "\n",
        "### Rename All Columns at Once\n",
        "\n",
        "```python\n",
        "data.columns = [col.capitalize() for col in data.columns]\n",
        "data.head()\n",
        "```\n",
        "\n",
        "**Tips:**\n",
        "\n",
        "* Use short, descriptive names\n",
        "* Stick to a consistent style (e.g., snake_case)\n",
        "* Avoid spaces and special characters\n",
        "\n",
        "---\n",
        "\n",
        "## 3️⃣ Dropping Duplicates\n",
        "\n",
        "```python\n",
        "# Check duplicate rows\n",
        "data.duplicated().sum()\n",
        "\n",
        "# Drop duplicate rows\n",
        "data.drop_duplicates(inplace=True)\n",
        "\n",
        "# Confirm duplicates removed\n",
        "data.duplicated().sum()\n",
        "```\n",
        "\n",
        "**Optional:** Drop duplicates based on specific columns or keep the last occurrence:\n",
        "\n",
        "```python\n",
        "data.drop_duplicates(subset=['column_name'], keep='last', inplace=True)\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## 4️⃣ & 5️⃣ Handling Missing Values\n",
        "\n",
        "### Detect Missing Values\n",
        "\n",
        "```python\n",
        "data.isna().sum()\n",
        "```\n",
        "\n",
        "### Remove Missing Values\n",
        "\n",
        "```python\n",
        "# Drop rows with any NaN\n",
        "data.dropna(inplace=True)\n",
        "\n",
        "# Reset index after dropping rows\n",
        "data.reset_index(drop=True, inplace=True)\n",
        "data.head()\n",
        "```\n",
        "\n",
        "**Optional:** Drop columns with NaN or specific rows:\n",
        "\n",
        "```python\n",
        "# Drop columns with any NaN\n",
        "# data.dropna(axis=1, inplace=True)\n",
        "\n",
        "# Drop rows only if all values are NaN\n",
        "# data.dropna(how='all', inplace=True)\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## 6️⃣ Cleaning Individual Columns\n",
        "\n",
        "### 1. Remove Leading/Trailing Spaces\n",
        "\n",
        "```python\n",
        "data['column_name'] = data['column_name'].str.strip()\n",
        "```\n",
        "\n",
        "### 2. Convert Data Types\n",
        "\n",
        "```python\n",
        "data['column_name'] = data['column_name'].astype(int)\n",
        "```\n",
        "\n",
        "### 3. Handle Missing Values in a Column\n",
        "\n",
        "```python\n",
        "data['column_name'].fillna(value, inplace=True)\n",
        "# or drop rows\n",
        "# data.dropna(subset=['column_name'], inplace=True)\n",
        "```\n",
        "\n",
        "### 4. Replace Specific Values\n",
        "\n",
        "```python\n",
        "data['column_name'].replace('old_value', 'new_value', inplace=True)\n",
        "```\n",
        "\n",
        "### 5. Apply Custom Functions\n",
        "\n",
        "```python\n",
        "data['column_name'] = data['column_name'].apply(lambda x: x.lower())\n",
        "```\n",
        "\n",
        "**Example: Cleaning \"Rate\" column**\n",
        "\n",
        "```python\n",
        "data[\"Rate\"] = data[\"Rate\"].str.replace(\"/\", \" out of \")\n",
        "data.head()\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## 7️⃣ Data Transformations\n",
        "\n",
        "### Apply Functions or Map Values\n",
        "\n",
        "```python\n",
        "# Convert text to uppercase\n",
        "data['column_name'] = data['column_name'].apply(lambda x: x.upper())\n",
        "\n",
        "# Map specific values\n",
        "data['column_name'] = data['column_name'].map({\"old_value\": \"new_value\"})\n",
        "```\n",
        "\n",
        "### Create New Columns\n",
        "\n",
        "```python\n",
        "data['new_column'] = data['col1'] + data['col2']\n",
        "data['is_high'] = data['col3'] > 100\n",
        "```\n",
        "\n",
        "### Handle Categorical Data\n",
        "\n",
        "```python\n",
        "# Label encoding\n",
        "data['category'] = data['category'].astype('category').cat.codes\n",
        "\n",
        "# One-hot encoding\n",
        "data = pd.get_dummies(data, columns=['category'])\n",
        "```\n",
        "\n",
        "### Scaling and Normalization\n",
        "\n",
        "```python\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "data[['col1', 'col2']] = scaler.fit_transform(data[['col1', 'col2']])\n",
        "```\n",
        "\n",
        "### Combining Columns or Rows\n",
        "\n",
        "```python\n",
        "data['full_name'] = data['first_name'] + \" \" + data['last_name']\n",
        "grouped = data.groupby('category')['sales'].sum()\n",
        "```\n",
        "\n",
        "**Tips:**\n",
        "\n",
        "* Always check your data after transformations with `.head()` or `.info()`\n",
        "* Avoid overwriting original columns unless necessary\n",
        "* Transformations simplify analysis and modeling\n",
        "\n",
        "---\n",
        "\n",
        "This version is **well-structured, beginner-friendly, and ready for Colab Markdown and code cells**.\n",
        "\n",
        "If you want, I can also create a **fully condensed notebook version** that combines explanations and code in **fewer cells** for faster execution and readability. Do you want me to do that?\n"
      ],
      "metadata": {
        "id": "oj-B_Teg93wV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lTzdcaVT4NWr",
        "outputId": "0c7e0b53-50a3-47f9-fd0b-dad0c46854db"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: opendatasets in /usr/local/lib/python3.12/dist-packages (0.1.22)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from opendatasets) (4.67.1)\n",
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.12/dist-packages (from opendatasets) (1.7.4.5)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from opendatasets) (8.3.1)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.12/dist-packages (from kaggle->opendatasets) (6.3.0)\n",
            "Requirement already satisfied: certifi>=14.05.14 in /usr/local/lib/python3.12/dist-packages (from kaggle->opendatasets) (2025.11.12)\n",
            "Requirement already satisfied: charset-normalizer in /usr/local/lib/python3.12/dist-packages (from kaggle->opendatasets) (3.4.4)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from kaggle->opendatasets) (3.11)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from kaggle->opendatasets) (5.29.5)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.12/dist-packages (from kaggle->opendatasets) (2.9.0.post0)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.12/dist-packages (from kaggle->opendatasets) (8.0.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from kaggle->opendatasets) (2.32.4)\n",
            "Requirement already satisfied: setuptools>=21.0.0 in /usr/local/lib/python3.12/dist-packages (from kaggle->opendatasets) (75.2.0)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.12/dist-packages (from kaggle->opendatasets) (1.17.0)\n",
            "Requirement already satisfied: text-unidecode in /usr/local/lib/python3.12/dist-packages (from kaggle->opendatasets) (1.3)\n",
            "Requirement already satisfied: urllib3>=1.15.1 in /usr/local/lib/python3.12/dist-packages (from kaggle->opendatasets) (2.5.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.12/dist-packages (from kaggle->opendatasets) (0.5.1)\n",
            "2.2.2\n",
            "Skipping, found downloaded files in \"./zomato\" (use force=True to force download)\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 51717 entries, 0 to 51716\n",
            "Data columns (total 17 columns):\n",
            " #   Column                       Non-Null Count  Dtype \n",
            "---  ------                       --------------  ----- \n",
            " 0   url                          51717 non-null  object\n",
            " 1   address                      51717 non-null  object\n",
            " 2   name                         51717 non-null  object\n",
            " 3   online_order                 51717 non-null  object\n",
            " 4   book_table                   51717 non-null  object\n",
            " 5   rate                         43942 non-null  object\n",
            " 6   votes                        51717 non-null  int64 \n",
            " 7   phone                        50509 non-null  object\n",
            " 8   location                     51696 non-null  object\n",
            " 9   rest_type                    51490 non-null  object\n",
            " 10  dish_liked                   23639 non-null  object\n",
            " 11  cuisines                     51672 non-null  object\n",
            " 12  approx_cost(for two people)  51371 non-null  object\n",
            " 13  reviews_list                 51717 non-null  object\n",
            " 14  menu_item                    51717 non-null  object\n",
            " 15  listed_in(type)              51717 non-null  object\n",
            " 16  listed_in(city)              51717 non-null  object\n",
            "dtypes: int64(1), object(16)\n",
            "memory usage: 6.7+ MB\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(51717, 17)"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ],
      "source": [
        "## Install and Load Data\n",
        "\n",
        "!pip install opendatasets\n",
        "\n",
        "import pandas as pd\n",
        "import opendatasets as od\n",
        "\n",
        "print(pd.__version__)\n",
        "\n",
        "# Download dataset from Kaggle\n",
        "od.download(\"https://www.kaggle.com/datasets/rishikeshkonapure/zomato\")\n",
        "\n",
        "# Load CSV file\n",
        "data = pd.read_csv(\"/content/zomato/zomato.csv\")\n",
        "\n",
        "# Inspect data\n",
        "data.head(2)\n",
        "data.columns\n",
        "data.info()\n",
        "data.shape"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VSPgpkaY6j1w",
        "outputId": "c96f0f19-2b3d-4643-f903-096d358e30c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.2.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import opendatasets as od\n",
        "od.download(\"https://www.kaggle.com/datasets/rishikeshkonapure/zomato\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7wHRKLaA692Z",
        "outputId": "a79b6142-f9af-41ce-86c9-0d4c23da6e3f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Skipping, found downloaded files in \"./zomato\" (use force=True to force download)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7yY4lVHf_RIi"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}